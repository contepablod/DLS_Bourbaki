{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Colegio Bourbaki](./Images/Bourbaki.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning & AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción a Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2vec desde cero en PyTorch\n",
    "\n",
    " Todo esto está basado en el gran trabajo de [Nejc Ilenic](https://github.com/inejc/paragraph-vectors) y el código fuente de gensim.\n",
    "\n",
    "`doc2vec` desciende de `word2vec`, cuya forma básica es que es un modelo entrenado para predecir la palabra que falta en un contexto. Dadas frases como \"el gato ___ en la alfombra\" debería predecir \"se sentó\", y al hacerlo aprende una representación útil de las palabras. A continuación, podemos extraer las ponderaciones internas y reutilizarlas como \"incrustaciones o encajes de palabras\", vectores que dan a cada palabra una posición en un espacio de N dimensiones que se espera que esté cerca de palabras similares y a una distancia adecuada de las palabras relacionadas. \n",
    "\n",
    "Doc2vec\" o \"vectores de párrafo\" amplía la idea de \"word2vec\" añadiendo un identificador de documento a cada contexto. Esto ayuda a la red a aprender asociaciones entre contextos y produce vectores que posicionan cada párrafo (documento) en el espacio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero tenemos que cargar los datos. Empezaremos sobreajustando un pequeño conjunto de datos para comprobar que todas las piezas encajan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the week before their departure to Arrakis, when all the final scurrying about had reached a ...</td>\n",
       "      <td>[in, the, week, before, their, departure, to, arrakis, when, all, the, final, scurrying, about, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was a warm night at Castle Caladan, and the ancient pile of stone that had served the Atreide...</td>\n",
       "      <td>[it, was, a, warm, night, at, castle, caladan, and, the, ancient, pile, of, stone, that, had, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The old woman was let in by the side door down the vaulted passage by Paul's room and she was al...</td>\n",
       "      <td>[the, old, woman, was, let, in, by, the, side, door, down, the, vaulted, passage, by, paul, room...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>By the half-light of a suspensor lamp, dimmed and hanging near the floor, the awakened boy could...</td>\n",
       "      <td>[by, the, half, light, of, a, suspensor, lamp, dimmed, and, hanging, near, the, floor, the, awak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0  In the week before their departure to Arrakis, when all the final scurrying about had reached a ...   \n",
       "1  It was a warm night at Castle Caladan, and the ancient pile of stone that had served the Atreide...   \n",
       "2  The old woman was let in by the side door down the vaulted passage by Paul's room and she was al...   \n",
       "3  By the half-light of a suspensor lamp, dimmed and hanging near the floor, the awakened boy could...   \n",
       "\n",
       "                                                                                                tokens  \n",
       "0  [in, the, week, before, their, departure, to, arrakis, when, all, the, final, scurrying, about, ...  \n",
       "1  [it, was, a, warm, night, at, castle, caladan, and, the, ancient, pile, of, stone, that, had, se...  \n",
       "2  [the, old, woman, was, let, in, by, the, side, door, down, the, vaulted, passage, by, paul, room...  \n",
       "3  [by, the, half, light, of, a, suspensor, lamp, dimmed, and, hanging, near, the, floor, the, awak...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 100)\n",
    "\n",
    "example_df = pd.read_csv(\"./Data/example.csv\")\n",
    "\n",
    "def tokenize_text(df):\n",
    "    df[\"tokens\"] = df.text.str.lower().str.strip().apply(lambda x: [token.text.strip() for token in nlp(x) if token.text.isalnum()])\n",
    "    return df\n",
    "\n",
    "example_df = tokenize_text(example_df)\n",
    "\n",
    "example_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construiremos un vocabulario para poder referenciar cada palabra por un ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset comprises 4 documents and 106 unique words (over the limit of 1 occurrences)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, all_tokens, min_count=2):\n",
    "        self.min_count = min_count\n",
    "        self.freqs = {t:n for t, n in Counter(all_tokens).items() if n >= min_count}\n",
    "        self.words = sorted(self.freqs.keys())\n",
    "        self.word2idx = {w: i for i, w in enumerate(self.words)}\n",
    "        \n",
    "vocab = Vocab([tok for tokens in example_df.tokens for tok in tokens], min_count=1)\n",
    "\n",
    "print(f\"Dataset comprises {len(example_df)} documents and {len(vocab.words)} unique words (over the limit of {vocab.min_count} occurrences)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las palabras que aparecen muy raramente pueden perjudicar el rendimiento, por lo que añadimos un mecanismo sencillo para eliminarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>length</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>clean_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the week before their departure to Arrakis, when all the final scurrying about had reached a ...</td>\n",
       "      <td>[in, the, week, before, their, departure, to, arrakis, when, all, the, final, scurrying, about, ...</td>\n",
       "      <td>32</td>\n",
       "      <td>[in, the, week, before, their, departure, to, arrakis, when, all, the, final, scurrying, about, ...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was a warm night at Castle Caladan, and the ancient pile of stone that had served the Atreide...</td>\n",
       "      <td>[it, was, a, warm, night, at, castle, caladan, and, the, ancient, pile, of, stone, that, had, se...</td>\n",
       "      <td>39</td>\n",
       "      <td>[it, was, a, warm, night, at, castle, caladan, and, the, ancient, pile, of, stone, that, had, se...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The old woman was let in by the side door down the vaulted passage by Paul's room and she was al...</td>\n",
       "      <td>[the, old, woman, was, let, in, by, the, side, door, down, the, vaulted, passage, by, paul, room...</td>\n",
       "      <td>34</td>\n",
       "      <td>[the, old, woman, was, let, in, by, the, side, door, down, the, vaulted, passage, by, paul, room...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>By the half-light of a suspensor lamp, dimmed and hanging near the floor, the awakened boy could...</td>\n",
       "      <td>[by, the, half, light, of, a, suspensor, lamp, dimmed, and, hanging, near, the, floor, the, awak...</td>\n",
       "      <td>53</td>\n",
       "      <td>[by, the, half, light, of, a, suspensor, lamp, dimmed, and, hanging, near, the, floor, the, awak...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0  In the week before their departure to Arrakis, when all the final scurrying about had reached a ...   \n",
       "1  It was a warm night at Castle Caladan, and the ancient pile of stone that had served the Atreide...   \n",
       "2  The old woman was let in by the side door down the vaulted passage by Paul's room and she was al...   \n",
       "3  By the half-light of a suspensor lamp, dimmed and hanging near the floor, the awakened boy could...   \n",
       "\n",
       "                                                                                                tokens  \\\n",
       "0  [in, the, week, before, their, departure, to, arrakis, when, all, the, final, scurrying, about, ...   \n",
       "1  [it, was, a, warm, night, at, castle, caladan, and, the, ancient, pile, of, stone, that, had, se...   \n",
       "2  [the, old, woman, was, let, in, by, the, side, door, down, the, vaulted, passage, by, paul, room...   \n",
       "3  [by, the, half, light, of, a, suspensor, lamp, dimmed, and, hanging, near, the, floor, the, awak...   \n",
       "\n",
       "   length  \\\n",
       "0      32   \n",
       "1      39   \n",
       "2      34   \n",
       "3      53   \n",
       "\n",
       "                                                                                          clean_tokens  \\\n",
       "0  [in, the, week, before, their, departure, to, arrakis, when, all, the, final, scurrying, about, ...   \n",
       "1  [it, was, a, warm, night, at, castle, caladan, and, the, ancient, pile, of, stone, that, had, se...   \n",
       "2  [the, old, woman, was, let, in, by, the, side, door, down, the, vaulted, passage, by, paul, room...   \n",
       "3  [by, the, half, light, of, a, suspensor, lamp, dimmed, and, hanging, near, the, floor, the, awak...   \n",
       "\n",
       "   clean_length  \n",
       "0            32  \n",
       "1            39  \n",
       "2            34  \n",
       "3            53  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_tokens(df, vocab):\n",
    "    df[\"length\"] = df.tokens.apply(len)\n",
    "    df[\"clean_tokens\"] = df.tokens.apply(lambda x: [t for t in x if t in vocab.freqs.keys()])\n",
    "    df[\"clean_length\"] = df.clean_tokens.apply(len)\n",
    "    return df\n",
    "\n",
    "example_df = clean_tokens(example_df, vocab)\n",
    "example_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La dificultad de nuestro problema \"el gato _ en la alfombra\" es que la palabra que falta podría ser cualquiera del vocabulario V y, por tanto, la red tendría salidas |V| para cada entrada, por ejemplo, un enorme vector con cero para cada palabra del vocabulario y algún número positivo para \"sat\" si la red estuviera perfectamente entrenada. Para calcular la pérdida, tenemos que convertirlo en una distribución de probabilidad, es decir, en un \"softmax\". Calcular el softmax para un vector tan grande es costoso.\n",
    "\n",
    "Así que el truco (uno de los muchos posibles) que utilizaremos es la Estimación Contrastiva de Ruido (NCE). Cambiamos nuestro problema \"el gato ___ en la alfombra\" por un problema de elección múltiple, pidiendo a la red que elija entre \"se sentó\" y algunas respuestas erróneas aleatorias como \"rayuela\" y \"se deleitó\". Esto es más fácil de calcular porque ahora es un clasificador binario (respuesta correcta o incorrecta) y la salida es simplemente un vector de tamaño 1 + k, donde k es el número de opciones incorrectas aleatorias.\n",
    "\n",
    "Afortunadamente, este problema alternativo sigue aprendiendo representaciones de palabras igualmente útiles. Sólo tenemos que ajustar los ejemplos y la función de pérdida. Existe una versión simplificada de la función de pérdida NCE llamada Muestreo Negativo (NEG) que podemos utilizar aquí.\n",
    "\n",
    "Cuando aplicamos la función de pérdida, suponemos que el primer elemento de un vector muestras/puntuaciones es la puntuación de la muestra positiva y el resto son muestras negativas. Esta convención nos evita tener que pasar un vector auxiliar que indique qué muestra fue positiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NegativeSampling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NegativeSampling, self).__init__()\n",
    "        self.log_sigmoid = nn.LogSigmoid()\n",
    "    def forward(self, scores):\n",
    "        batch_size = scores.shape[0]\n",
    "        n_negative_samples = scores.shape[1] - 1   # TODO average or sum the negative samples? Summing seems to be correct by the paper\n",
    "        positive = self.log_sigmoid(scores[:,0])\n",
    "        negatives = torch.sum(self.log_sigmoid(-scores[:,1:]), dim=1)\n",
    "        return -torch.sum(positive + negatives) / batch_size  # average for batch\n",
    "\n",
    "loss = NegativeSampling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es útil jugar con algunos valores para asegurarnos de que esta función hace lo correcto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, -1, -1, -1]</td>\n",
       "      <td>tensor(1.2530)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.5, -1, -1, -1]</td>\n",
       "      <td>tensor(1.4139)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0, -1, -1, -1]</td>\n",
       "      <td>tensor(1.6329)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>tensor(2.7726)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0, 0, 1]</td>\n",
       "      <td>tensor(3.3927)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0, 1, 1, 1]</td>\n",
       "      <td>tensor(4.6329)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.5, 1, 1, 1]</td>\n",
       "      <td>tensor(4.4139)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>tensor(4.2530)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              scores            loss\n",
       "0    [1, -1, -1, -1]  tensor(1.2530)\n",
       "1  [0.5, -1, -1, -1]  tensor(1.4139)\n",
       "2    [0, -1, -1, -1]  tensor(1.6329)\n",
       "3       [0, 0, 0, 0]  tensor(2.7726)\n",
       "4       [0, 0, 0, 1]  tensor(3.3927)\n",
       "5       [0, 1, 1, 1]  tensor(4.6329)\n",
       "6     [0.5, 1, 1, 1]  tensor(4.4139)\n",
       "7       [1, 1, 1, 1]  tensor(4.2530)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "data = [[[1, -1, -1, -1]],  # this dummy data uses -1 to 1, but the real model is unconstrained\n",
    "        [[0.5, -1, -1, -1]],\n",
    "        [[0, -1, -1, -1]],\n",
    "        [[0, 0, 0, 0]],\n",
    "        [[0, 0, 0, 1]],\n",
    "        [[0, 1, 1, 1]],\n",
    "        [[0.5, 1, 1, 1]],\n",
    "        [[1, 1, 1, 1]]]\n",
    "\n",
    "loss_df = pd.DataFrame(data, columns=[\"scores\"])\n",
    "loss_df[\"loss\"] = loss_df.scores.apply(lambda x: loss(torch.FloatTensor([x])))\n",
    "\n",
    "loss_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las puntuaciones más altas de la muestra positiva (siempre el primer elemento) reducen la pérdida, pero las puntuaciones más altas de las muestras negativas aumentan la pérdida. Este parece el comportamiento correcto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto en la mochila, veamos cómo crear datos de entrenamiento. La idea general es crear un conjunto de ejemplos donde cada ejemplo tiene:\n",
    "\n",
    "- doc id\n",
    "- ids de muestra - una colección del token objetivo y algunos tokens de ruido\n",
    "- ids de contexto - tokens antes y después del token objetivo\n",
    "\n",
    "Por ejemplo, si el tamaño de nuestro contexto fuera 2, el primer ejemplo del conjunto de datos anterior sería:\n",
    "\n",
    "```\n",
    "{\"doc_id\": 0,\n",
    " \"sample_ids\": [word2idx[x] for x in [\"semana\", \"palabra-aleatoria-de-vocab\", \"palabra-aleatoria-de-vocab\"...],\n",
    " \"context_ids\": [word2idx[x] for x in [\"en\", \"el\", \"antes\", \"sus\"]]}\n",
    " ```\n",
    " \n",
    " Las palabras aleatorias se eligen según una distribución de probabilidad:\n",
    " \n",
    " > una distribución de unigramas elevada a la 3/4ª potencia, como proponen T. Mikolov et al. en Distributed Representations of Words and Phrases and their Compositionality.\n",
    "\n",
    "Esto tiene el efecto de aumentar ligeramente la probabilidad relativa de las palabras raras (mire el gráfico de `y=x^0,75` más abajo y vea cómo el extremo inferior se eleva por encima de `y=x`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-2e285eb3424447d983f9e3c830ce915e.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-2e285eb3424447d983f9e3c830ce915e.vega-embed details,\n",
       "  #altair-viz-2e285eb3424447d983f9e3c830ce915e.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-2e285eb3424447d983f9e3c830ce915e\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-2e285eb3424447d983f9e3c830ce915e\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-2e285eb3424447d983f9e3c830ce915e\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-afc3dc0951a9e12875119a5af86e52b5\"}, \"mark\": {\"type\": \"line\"}, \"encoding\": {\"x\": {\"field\": \"x\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"y\", \"type\": \"quantitative\"}}, \"title\": \"x^0.75\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-afc3dc0951a9e12875119a5af86e52b5\": [{\"x\": 0.0, \"y\": 0.0}, {\"x\": 0.01, \"y\": 0.03162277660168379}, {\"x\": 0.02, \"y\": 0.053182958969449884}, {\"x\": 0.03, \"y\": 0.07208434242404263}, {\"x\": 0.04, \"y\": 0.08944271909999159}, {\"x\": 0.05, \"y\": 0.10573712634405642}, {\"x\": 0.06, \"y\": 0.12123093028059741}, {\"x\": 0.07, \"y\": 0.13608915892697748}, {\"x\": 0.08, \"y\": 0.15042412372345573}, {\"x\": 0.09, \"y\": 0.16431676725154984}, {\"x\": 0.1, \"y\": 0.1778279410038923}, {\"x\": 0.11, \"y\": 0.19100490227716513}, {\"x\": 0.12, \"y\": 0.2038853093816547}, {\"x\": 0.13, \"y\": 0.2164998073464082}, {\"x\": 0.14, \"y\": 0.22887377179317683}, {\"x\": 0.15, \"y\": 0.2410285256833955}, {\"x\": 0.16, \"y\": 0.25298221281347033}, {\"x\": 0.17, \"y\": 0.26475044029330763}, {\"x\": 0.18, \"y\": 0.2763467610958144}, {\"x\": 0.19, \"y\": 0.28778304315451386}, {\"x\": 0.2, \"y\": 0.29906975624424414}, {\"x\": 0.21, \"y\": 0.3102161981490854}, {\"x\": 0.22, \"y\": 0.32123067524150845}, {\"x\": 0.23, \"y\": 0.33212064831351956}, {\"x\": 0.24, \"y\": 0.34289285156385596}, {\"x\": 0.25, \"y\": 0.3535533905932738}, {\"x\": 0.26, \"y\": 0.3641078238014289}, {\"x\": 0.27, \"y\": 0.37456123052590357}, {\"x\": 0.28, \"y\": 0.38491826849295824}, {\"x\": 0.29, \"y\": 0.39518322257770583}, {\"x\": 0.3, \"y\": 0.4053600464421103}, {\"x\": 0.31, \"y\": 0.41545239829339137}, {\"x\": 0.32, \"y\": 0.42546367175559907}, {\"x\": 0.33, \"y\": 0.43539702265375557}, {\"x\": 0.34, \"y\": 0.4452553923589699}, {\"x\": 0.35000000000000003, \"y\": 0.45504152822405847}, {\"x\": 0.36, \"y\": 0.46475800154489}, {\"x\": 0.37, \"y\": 0.47440722340731084}, {\"x\": 0.38, \"y\": 0.4839914587188715}, {\"x\": 0.39, \"y\": 0.4935128386754873}, {\"x\": 0.4, \"y\": 0.5029733718731741}, {\"x\": 0.41000000000000003, \"y\": 0.5123749542422491}, {\"x\": 0.42, \"y\": 0.5217193779544038}, {\"x\": 0.43, \"y\": 0.5310083394307343}, {\"x\": 0.44, \"y\": 0.5402434465602292}, {\"x\": 0.45, \"y\": 0.549426225222706}, {\"x\": 0.46, \"y\": 0.5585581251971565}, {\"x\": 0.47000000000000003, \"y\": 0.5676405255254853}, {\"x\": 0.48, \"y\": 0.576674739392341}, {\"x\": 0.49, \"y\": 0.5856620185738529}, {\"x\": 0.5, \"y\": 0.5946035575013605}, {\"x\": 0.51, \"y\": 0.6035004969804791}, {\"x\": 0.52, \"y\": 0.6123539276009055}, {\"x\": 0.53, \"y\": 0.6211648928681236}, {\"x\": 0.54, \"y\": 0.629934392084505}, {\"x\": 0.55, \"y\": 0.6386633830041155}, {\"x\": 0.56, \"y\": 0.6473527842827909}, {\"x\": 0.5700000000000001, \"y\": 0.6560034777426358}, {\"x\": 0.58, \"y\": 0.6646163104680073}, {\"x\": 0.59, \"y\": 0.6731920967482075}, {\"x\": 0.6, \"y\": 0.6817316198804996}, {\"x\": 0.61, \"y\": 0.6902356338456498}, {\"x\": 0.62, \"y\": 0.6987048648669424}, {\"x\": 0.63, \"y\": 0.7071400128625219}, {\"x\": 0.64, \"y\": 0.7155417527999327}, {\"x\": 0.65, \"y\": 0.7239107359608682}, {\"x\": 0.66, \"y\": 0.7322475911233668}, {\"x\": 0.67, \"y\": 0.7405529256680135}, {\"x\": 0.68, \"y\": 0.7488273266140879}, {\"x\": 0.6900000000000001, \"y\": 0.7570713615910638}, {\"x\": 0.7000000000000001, \"y\": 0.7652855797503655}, {\"x\": 0.71, \"y\": 0.7734705126218591}, {\"x\": 0.72, \"y\": 0.7816266749191567}, {\"x\": 0.73, \"y\": 0.7897545652974598}, {\"x\": 0.74, \"y\": 0.7978546670673515}, {\"x\": 0.75, \"y\": 0.8059274488676564}, {\"x\": 0.76, \"y\": 0.8139733653002305}, {\"x\": 0.77, \"y\": 0.8219928575293057}, {\"x\": 0.78, \"y\": 0.829986353847804}, {\"x\": 0.79, \"y\": 0.837954270212839}, {\"x\": 0.8, \"y\": 0.8458970107524514}, {\"x\": 0.81, \"y\": 0.8538149682454624}, {\"x\": 0.8200000000000001, \"y\": 0.8617085245761865}, {\"x\": 0.8300000000000001, \"y\": 0.869578051165608}, {\"x\": 0.84, \"y\": 0.8774239093805121}, {\"x\": 0.85, \"y\": 0.8852464509219427}, {\"x\": 0.86, \"y\": 0.8930460181942644}, {\"x\": 0.87, \"y\": 0.9008229446560111}, {\"x\": 0.88, \"y\": 0.9085775551536168}, {\"x\": 0.89, \"y\": 0.9163101662390513}, {\"x\": 0.9, \"y\": 0.9240210864723069}, {\"x\": 0.91, \"y\": 0.9317106167096201}, {\"x\": 0.92, \"y\": 0.9393790503782488}, {\"x\": 0.93, \"y\": 0.9470266737385726}, {\"x\": 0.9400000000000001, \"y\": 0.9546537661342305}, {\"x\": 0.9500000000000001, \"y\": 0.9622606002309622}, {\"x\": 0.96, \"y\": 0.9698474422447793}, {\"x\": 0.97, \"y\": 0.9774145521600454}, {\"x\": 0.98, \"y\": 0.9849621839380145}, {\"x\": 0.99, \"y\": 0.992490585716335}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import numpy as np\n",
    "\n",
    "data = pd.DataFrame(zip(np.arange(0,1,0.01), np.power(np.arange(0,1,0.01), 0.75)), columns=[\"x\", \"y\"])\n",
    "alt.Chart(data, title=\"x^0.75\").mark_line().encode(x=\"x\", y=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NoiseDistribution:\n",
    "    def __init__(self, vocab):\n",
    "        self.probs = np.array([vocab.freqs[w] for w in vocab.words])\n",
    "        self.probs = np.power(self.probs, 0.75)\n",
    "        self.probs /= np.sum(self.probs)\n",
    "    def sample(self, n):\n",
    "        \"Returns the indices of n words randomly sampled from the vocabulary.\"\n",
    "        return np.random.choice(a=self.probs.shape[0], size=n, p=self.probs)\n",
    "        \n",
    "noise = NoiseDistribution(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta distribución, avanzamos por los documentos creando ejemplos. Tengamos en cuenta que siempre ponemos la muestra positiva en primer lugar en el vector de muestras, siguiendo la convención que espera la función de pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def example_generator(df, context_size, noise, n_negative_samples, vocab):\n",
    "    for doc_id, doc in df.iterrows():\n",
    "        for i in range(context_size, len(doc.clean_tokens) - context_size):\n",
    "            positive_sample = vocab.word2idx[doc.clean_tokens[i]]\n",
    "            sample_ids = noise.sample(n_negative_samples).tolist()\n",
    "            # Fix a wee bug - ensure negative samples don't accidentally include the positive\n",
    "            sample_ids = [sample_id if sample_id != positive_sample else -1 for sample_id in sample_ids]\n",
    "            sample_ids.insert(0, positive_sample)                \n",
    "            context = doc.clean_tokens[i - context_size:i] + doc.clean_tokens[i + 1:i + context_size + 1]\n",
    "            context_ids = [vocab.word2idx[w] for w in context]\n",
    "            yield {\"doc_ids\": torch.tensor(doc_id),  # we use plural here because it will be batched\n",
    "                   \"sample_ids\": torch.tensor(sample_ids), \n",
    "                   \"context_ids\": torch.tensor(context_ids)}\n",
    "            \n",
    "examples = example_generator(example_df, context_size=5, noise=noise, n_negative_samples=5, vocab=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora lo empaquetamos como un dataset y dataloader de PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class NCEDataset(Dataset):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = list(examples)  # just naively evaluate the whole damn thing - suboptimal!\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "    def __getitem__(self, index):\n",
    "        return self.examples[index]\n",
    "    \n",
    "dataset = NCEDataset(examples)\n",
    "dataloader = DataLoader(dataset, batch_size=2, drop_last=True, shuffle=True)  # TODO bigger batch size when not dummy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También va a ser útil tener una manera de convertir los lotes de nuevo a una forma legible para la depuración, por lo que añadimos una función de ayuda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'doc_id': tensor(2),\n",
       "  'context': 'the old woman was let ____ by the side door down',\n",
       "  'context_ids': tensor([ 91,  67, 105,  99,  57,  19,  91,  82,  30,  31]),\n",
       "  'samples': ['in', 'six', 'woman', 'change', 'change', 'the'],\n",
       "  'sample_ids': tensor([ 52,  83, 105,  23,  23,  91])},\n",
       " {'doc_id': tensor(3),\n",
       "  'context': 'light of a suspensor lamp ____ and hanging near the floor',\n",
       "  'context_ids': tensor([58, 66,  0, 88, 55,  8, 46, 63, 91, 38]),\n",
       "  'samples': ['dimmed', 'caladan', 'was', 'weather', 'a', 'his'],\n",
       "  'sample_ids': tensor([ 29,  20,  99, 100,   0,  49])}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def describe_batch(batch, vocab):\n",
    "    results = []\n",
    "    for doc_id, context_ids, sample_ids in zip(batch[\"doc_ids\"], batch[\"context_ids\"], batch[\"sample_ids\"]):\n",
    "        context = [vocab.words[i] for i in context_ids]\n",
    "        context.insert(len(context_ids) // 2, \"____\")\n",
    "        samples = [vocab.words[i] for i in sample_ids]\n",
    "        result = {\"doc_id\": doc_id,\n",
    "                  \"context\": \" \".join(context), \n",
    "                  \"context_ids\": context_ids, \n",
    "                  \"samples\": samples, \n",
    "                  \"sample_ids\": sample_ids}\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "describe_batch(next(iter(dataloader)), vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasemos a crear el modelo en sí. No hay mucho que hacer - multiplicamos las matrices de entrada de párrafos y palabras por la capa de salida. La combinación de las matrices de párrafos y palabras se hace sumando aquí, pero también podría hacerse concatenando las entradas. En el artículo original se descubrió que la concatenación funciona mejor, quizá porque al sumar se pierde información sobre el orden de las palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DistributedMemory(nn.Module):\n",
    "    def __init__(self, vec_dim, n_docs, n_words):\n",
    "        super(DistributedMemory, self).__init__()\n",
    "        self.paragraph_matrix = nn.Parameter(torch.randn(n_docs, vec_dim))\n",
    "        self.word_matrix = nn.Parameter(torch.randn(n_words, vec_dim))\n",
    "        self.outputs = nn.Parameter(torch.zeros(vec_dim, n_words))\n",
    "    \n",
    "    def forward(self, doc_ids, context_ids, sample_ids):\n",
    "                                                                               # first add doc ids to context word ids to make the inputs\n",
    "        inputs = torch.add(self.paragraph_matrix[doc_ids,:],                   # (batch_size, vec_dim)\n",
    "                           torch.sum(self.word_matrix[context_ids,:], dim=1))  # (batch_size, 2x context, vec_dim) -> sum to (batch_size, vec_dim)\n",
    "                                                                               #\n",
    "        # inputs = torch.cat(self.paragraph_matrix[doc_ids,:],                   # (batch_size, vec_dim)                                                                       # select the subset of the output layer for the NCE test\n",
    "        outputs = self.outputs[:,sample_ids]                                   # (vec_dim, batch_size, n_negative_samples + 1)\n",
    "                                                                               #\n",
    "        return torch.bmm(inputs.unsqueeze(dim=1),                              # then multiply with some munging to make the tensor shapes line up \n",
    "                         outputs.permute(1, 0, 2)).squeeze()                   # -> (batch_size, n_negative_samples + 1)\n",
    "\n",
    "model = DistributedMemory(vec_dim=50,\n",
    "                          n_docs=len(example_df),\n",
    "                          n_words=len(vocab.words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model.forward(**next(iter(dataloader)))\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La capa de salida se inicializó con ceros. Es hora de hacer un bucle de entrenamiento estándar de PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, trange\n",
    "from torch.optim import Adam  # ilenic uses Adam, but gensim uses plain SGD\n",
    "import numpy as np\n",
    "\n",
    "def train(model, dataloader, epochs=40, lr=1e-3):\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    training_losses = []\n",
    "    try:\n",
    "        for epoch in trange(epochs, desc=\"Epochs\"):\n",
    "            epoch_losses = []\n",
    "            for batch in dataloader:\n",
    "                model.zero_grad()\n",
    "                logits = model.forward(**batch)\n",
    "                batch_loss = loss(logits)\n",
    "                epoch_losses.append(batch_loss.item())\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            training_losses.append(np.mean(epoch_losses))\n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"Interrupted on epoch {epoch}!\")\n",
    "    finally:\n",
    "        return training_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora comprobaremos la integridad sobreajustando los datos de ejemplo. La pérdida de entrenamiento debería caer desde la pérdida no entrenada hasta algo cercano al mínimo posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 40/40 [00:02<00:00, 15.65it/s]\n"
     ]
    }
   ],
   "source": [
    "training_losses = train(model, dataloader, epochs=40, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-b757946fda6e43519f554b57f6eff380.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-b757946fda6e43519f554b57f6eff380.vega-embed details,\n",
       "  #altair-viz-b757946fda6e43519f554b57f6eff380.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-b757946fda6e43519f554b57f6eff380\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-b757946fda6e43519f554b57f6eff380\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-b757946fda6e43519f554b57f6eff380\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-a190c3937ef52df6aead66c5f74f782a\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"training_loss\", \"scale\": {\"type\": \"log\"}, \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-a190c3937ef52df6aead66c5f74f782a\": [{\"epoch\": 0, \"training_loss\": 3.9272449259030617}, {\"epoch\": 1, \"training_loss\": 2.6008586479445635}, {\"epoch\": 2, \"training_loss\": 1.9218272879972296}, {\"epoch\": 3, \"training_loss\": 1.5070471743405875}, {\"epoch\": 4, \"training_loss\": 1.2180714506213948}, {\"epoch\": 5, \"training_loss\": 1.0073063605922763}, {\"epoch\": 6, \"training_loss\": 0.8411663528216087}, {\"epoch\": 7, \"training_loss\": 0.7243558820021354}, {\"epoch\": 8, \"training_loss\": 0.6260695411997327}, {\"epoch\": 9, \"training_loss\": 0.5479717345561012}, {\"epoch\": 10, \"training_loss\": 0.4802964160502967}, {\"epoch\": 11, \"training_loss\": 0.4229362490823713}, {\"epoch\": 12, \"training_loss\": 0.3803033955016379}, {\"epoch\": 13, \"training_loss\": 0.3385489494618723}, {\"epoch\": 14, \"training_loss\": 0.3005468501883038}, {\"epoch\": 15, \"training_loss\": 0.2759657407463607}, {\"epoch\": 16, \"training_loss\": 0.24630464083057338}, {\"epoch\": 17, \"training_loss\": 0.2240412148126101}, {\"epoch\": 18, \"training_loss\": 0.20691331880072417}, {\"epoch\": 19, \"training_loss\": 0.18379020678289867}, {\"epoch\": 20, \"training_loss\": 0.17084230469950176}, {\"epoch\": 21, \"training_loss\": 0.15570673516998856}, {\"epoch\": 22, \"training_loss\": 0.14263466196292537}, {\"epoch\": 23, \"training_loss\": 0.13120749592781067}, {\"epoch\": 24, \"training_loss\": 0.12080346900275198}, {\"epoch\": 25, \"training_loss\": 0.1113655607579118}, {\"epoch\": 26, \"training_loss\": 0.10309351885975418}, {\"epoch\": 27, \"training_loss\": 0.09489752014435954}, {\"epoch\": 28, \"training_loss\": 0.08897291354329909}, {\"epoch\": 29, \"training_loss\": 0.08276049454964823}, {\"epoch\": 30, \"training_loss\": 0.07729824439827669}, {\"epoch\": 31, \"training_loss\": 0.07209492844166392}, {\"epoch\": 32, \"training_loss\": 0.06702955982695191}, {\"epoch\": 33, \"training_loss\": 0.0627509351125208}, {\"epoch\": 34, \"training_loss\": 0.05870718996719283}, {\"epoch\": 35, \"training_loss\": 0.05567680008835712}, {\"epoch\": 36, \"training_loss\": 0.05215181369271319}, {\"epoch\": 37, \"training_loss\": 0.04859379660022461}, {\"epoch\": 38, \"training_loss\": 0.04607495891277568}, {\"epoch\": 39, \"training_loss\": 0.04339450724044089}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "df_loss = pd.DataFrame(enumerate(training_losses), columns=[\"epoch\", \"training_loss\"])\n",
    "alt.Chart(df_loss).mark_bar().encode(alt.X(\"epoch\"), alt.Y(\"training_loss\", scale=alt.Scale(type=\"log\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And because we're paranoid types, let's check a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.8161, -3.9632, -6.8090, -5.7780, -5.3816, -7.0874],\n",
       "        [ 3.9666, -5.0719, -6.5105, -5.6400, -6.0204, -6.5624]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model.forward(**next(iter(dataloader)))\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La muestra positiva obtiene una puntuación positiva y las negativas, una puntuación negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deberíamos poder obtener los vectores de párrafo de los documentos y hacer cosas como comprobar la similitud entre ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>It was a warm night at Castle Caladan, and the ancient pile of stone that had served the Atreide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.064187</td>\n",
       "      <td>In the week before their departure to Arrakis, when all the final scurrying about had reached a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.128808</td>\n",
       "      <td>The old woman was let in by the side door down the vaulted passage by Paul's room and she was al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.270460</td>\n",
       "      <td>By the half-light of a suspensor lamp, dimmed and hanging near the floor, the awakened boy could...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  similarity  \\\n",
       "1       1    1.000000   \n",
       "0       0    0.064187   \n",
       "2       2   -0.128808   \n",
       "3       3   -0.270460   \n",
       "\n",
       "                                                                                                  text  \n",
       "1  It was a warm night at Castle Caladan, and the ancient pile of stone that had served the Atreide...  \n",
       "0  In the week before their departure to Arrakis, when all the final scurrying about had reached a ...  \n",
       "2  The old woman was let in by the side door down the vaulted passage by Paul's room and she was al...  \n",
       "3  By the half-light of a suspensor lamp, dimmed and hanging near the floor, the awakened boy could...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def most_similar(paragraph_matrix, docs_df, index, n=None):\n",
    "    pm = normalize(paragraph_matrix, norm=\"l2\")  # in a smarter implementation we would cache this somewhere\n",
    "    sims = np.dot(pm, pm[index,:])\n",
    "    df = pd.DataFrame(enumerate(sims), columns=[\"doc_id\", \"similarity\"])\n",
    "    n = n if n is not None else len(sims)\n",
    "    return df.merge(docs_df[[\"text\"]].reset_index(drop=True), left_index=True, right_index=True).sort_values(by=\"similarity\", ascending=False)[:n]\n",
    "\n",
    "most_similar(model.paragraph_matrix.data, example_df, 1, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, no es especialmente esclarecedor para nuestro pequeño conjunto de datos ficticios. También podemos utilizar PCA para reducir nuestros vectores de párrafos n-dimensionales a 2 dimensiones y ver si se agrupan bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-component PCA, explains 45.13% of variance\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-1b51e9889b414191be50db8c8bef7115.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-1b51e9889b414191be50db8c8bef7115.vega-embed details,\n",
       "  #altair-viz-1b51e9889b414191be50db8c8bef7115.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-1b51e9889b414191be50db8c8bef7115\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-1b51e9889b414191be50db8c8bef7115\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-1b51e9889b414191be50db8c8bef7115\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-79cdb8f9be9155e5edea954c335653ca\"}, \"mark\": {\"type\": \"point\"}, \"encoding\": {\"color\": {\"field\": \"group\", \"type\": \"nominal\"}, \"x\": {\"field\": \"x\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"y\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-79cdb8f9be9155e5edea954c335653ca\": [{\"x\": 3.171890427669916, \"y\": -4.384594207406089, \"group\": \"0\"}, {\"x\": 5.2885416938212835, \"y\": 3.1210226037169444, \"group\": \"1\"}, {\"x\": -3.8844532118658828, \"y\": 4.604125700854517, \"group\": \"2\"}, {\"x\": -4.575978909625313, \"y\": -3.340554097165377, \"group\": \"3\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def pca_2d(paragraph_matrix, groups):\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_dims = pca.fit_transform(paragraph_matrix)\n",
    "    print(f\"2-component PCA, explains {sum(pca.explained_variance_):.2f}% of variance\")\n",
    "    df = pd.DataFrame(reduced_dims, columns=[\"x\", \"y\"])\n",
    "    df[\"group\"] = groups\n",
    "    return df\n",
    "\n",
    "example_2d = pca_2d(model.paragraph_matrix.data, [\"0\",\"1\",\"2\",\"3\"])\n",
    "alt.Chart(example_2d).mark_point().encode(x=\"x\", y=\"y\", color=\"group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No hay mucho que ver en un conjunto de datos tan pequeño sin grupos etiquetados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutando esto en algunos datos más grandes, utilizaremos el conjunto de datos de la BBC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Claxton hunting first major medal  British hurdler Sarah Claxton is confident she can win her fi...</td>\n",
       "      <td>[claxton, hunting, first, major, medal, british, hurdler, sarah, claxton, is, confident, she, ca...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O'Sullivan could run in Worlds  Sonia O'Sullivan has indicated that she would like to participat...</td>\n",
       "      <td>[could, run, in, worlds, sonia, has, indicated, that, she, would, like, to, participate, in, nex...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Greene sets sights on world title  Maurice Greene aims to wipe out the pain of losing his Olympi...</td>\n",
       "      <td>[greene, sets, sights, on, world, title, maurice, greene, aims, to, wipe, out, the, pain, of, lo...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IAAF launches fight against drugs  The IAAF - athletics' world governing body - has met anti-dop...</td>\n",
       "      <td>[iaaf, launches, fight, against, drugs, the, iaaf, athletics, world, governing, body, has, met, ...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0  Claxton hunting first major medal  British hurdler Sarah Claxton is confident she can win her fi...   \n",
       "1  O'Sullivan could run in Worlds  Sonia O'Sullivan has indicated that she would like to participat...   \n",
       "2  Greene sets sights on world title  Maurice Greene aims to wipe out the pain of losing his Olympi...   \n",
       "3  IAAF launches fight against drugs  The IAAF - athletics' world governing body - has met anti-dop...   \n",
       "\n",
       "                                                                                                tokens  \\\n",
       "0  [claxton, hunting, first, major, medal, british, hurdler, sarah, claxton, is, confident, she, ca...   \n",
       "1  [could, run, in, worlds, sonia, has, indicated, that, she, would, like, to, participate, in, nex...   \n",
       "2  [greene, sets, sights, on, world, title, maurice, greene, aims, to, wipe, out, the, pain, of, lo...   \n",
       "3  [iaaf, launches, fight, against, drugs, the, iaaf, athletics, world, governing, body, has, met, ...   \n",
       "\n",
       "   group  \n",
       "0  sport  \n",
       "1  sport  \n",
       "2  sport  \n",
       "3  sport  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for document_set in (\"sport\",\n",
    "                     \"business\",\n",
    "                     \"politics\", \n",
    "                     \"tech\", \n",
    "                     \"entertainment\"):\n",
    "    df_ = pd.read_csv(f\"./Data/bbc/{document_set}.csv.bz2\", encoding=\"latin1\")\n",
    "    df_ = tokenize_text(df_)\n",
    "    df_[\"group\"] = document_set\n",
    "    dfs.append(df_)\n",
    "\n",
    "bbc_df = pd.concat(dfs)\n",
    "bbc_df[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Claxton hunting first major medal  British hurdler Sarah Claxton is confident she can win her fi...</td>\n",
       "      <td>[claxton, hunting, first, major, medal, british, hurdler, sarah, claxton, is, confident, she, ca...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O'Sullivan could run in Worlds  Sonia O'Sullivan has indicated that she would like to participat...</td>\n",
       "      <td>[could, run, in, worlds, sonia, has, indicated, that, she, would, like, to, participate, in, nex...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Greene sets sights on world title  Maurice Greene aims to wipe out the pain of losing his Olympi...</td>\n",
       "      <td>[greene, sets, sights, on, world, title, maurice, greene, aims, to, wipe, out, the, pain, of, lo...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IAAF launches fight against drugs  The IAAF - athletics' world governing body - has met anti-dop...</td>\n",
       "      <td>[iaaf, launches, fight, against, drugs, the, iaaf, athletics, world, governing, body, has, met, ...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dibaba breaks 5,000m world record  Ethiopia's Tirunesh Dibaba set a new world record in winning ...</td>\n",
       "      <td>[dibaba, breaks, m, world, record, ethiopia, tirunesh, dibaba, set, a, new, world, record, in, w...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Isinbayeva claims new world best  Pole vaulter Yelena Isinbayeva broke her own indoor world reco...</td>\n",
       "      <td>[isinbayeva, claims, new, world, best, pole, vaulter, yelena, isinbayeva, broke, her, own, indoo...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>O'Sullivan commits to Dublin race  Sonia O'Sullivan will seek to regain her title at the Bupa Gr...</td>\n",
       "      <td>[commits, to, dublin, race, sonia, will, seek, to, regain, her, title, at, the, bupa, great, ire...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hansen 'delays return until 2006'  British triple jumper Ashia Hansen has ruled out a comeback t...</td>\n",
       "      <td>[hansen, delays, return, until, 2006, british, triple, jumper, ashia, hansen, has, ruled, out, a...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Off-colour Gardener storms to win  Britain's Jason Gardener shook off an upset stomach to win th...</td>\n",
       "      <td>[off, colour, gardener, storms, to, win, britain, jason, gardener, shook, off, an, upset, stomac...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Collins to compete in Birmingham  World and Commonwealth 100m champion Kim Collins will compete ...</td>\n",
       "      <td>[collins, to, compete, in, birmingham, world, and, commonwealth, 100, m, champion, kim, collins,...</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0  Claxton hunting first major medal  British hurdler Sarah Claxton is confident she can win her fi...   \n",
       "1  O'Sullivan could run in Worlds  Sonia O'Sullivan has indicated that she would like to participat...   \n",
       "2  Greene sets sights on world title  Maurice Greene aims to wipe out the pain of losing his Olympi...   \n",
       "3  IAAF launches fight against drugs  The IAAF - athletics' world governing body - has met anti-dop...   \n",
       "4  Dibaba breaks 5,000m world record  Ethiopia's Tirunesh Dibaba set a new world record in winning ...   \n",
       "5  Isinbayeva claims new world best  Pole vaulter Yelena Isinbayeva broke her own indoor world reco...   \n",
       "6  O'Sullivan commits to Dublin race  Sonia O'Sullivan will seek to regain her title at the Bupa Gr...   \n",
       "7  Hansen 'delays return until 2006'  British triple jumper Ashia Hansen has ruled out a comeback t...   \n",
       "8  Off-colour Gardener storms to win  Britain's Jason Gardener shook off an upset stomach to win th...   \n",
       "9  Collins to compete in Birmingham  World and Commonwealth 100m champion Kim Collins will compete ...   \n",
       "\n",
       "                                                                                                tokens  \\\n",
       "0  [claxton, hunting, first, major, medal, british, hurdler, sarah, claxton, is, confident, she, ca...   \n",
       "1  [could, run, in, worlds, sonia, has, indicated, that, she, would, like, to, participate, in, nex...   \n",
       "2  [greene, sets, sights, on, world, title, maurice, greene, aims, to, wipe, out, the, pain, of, lo...   \n",
       "3  [iaaf, launches, fight, against, drugs, the, iaaf, athletics, world, governing, body, has, met, ...   \n",
       "4  [dibaba, breaks, m, world, record, ethiopia, tirunesh, dibaba, set, a, new, world, record, in, w...   \n",
       "5  [isinbayeva, claims, new, world, best, pole, vaulter, yelena, isinbayeva, broke, her, own, indoo...   \n",
       "6  [commits, to, dublin, race, sonia, will, seek, to, regain, her, title, at, the, bupa, great, ire...   \n",
       "7  [hansen, delays, return, until, 2006, british, triple, jumper, ashia, hansen, has, ruled, out, a...   \n",
       "8  [off, colour, gardener, storms, to, win, britain, jason, gardener, shook, off, an, upset, stomac...   \n",
       "9  [collins, to, compete, in, birmingham, world, and, commonwealth, 100, m, champion, kim, collins,...   \n",
       "\n",
       "   group  \n",
       "0  sport  \n",
       "1  sport  \n",
       "2  sport  \n",
       "3  sport  \n",
       "4  sport  \n",
       "5  sport  \n",
       "6  sport  \n",
       "7  sport  \n",
       "8  sport  \n",
       "9  sport  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset comprises 2225 documents and 19065 unique words\n"
     ]
    }
   ],
   "source": [
    "bbc_vocab = Vocab([tok for tokens in bbc_df.tokens for tok in tokens])\n",
    "\n",
    "bbc_df = clean_tokens(bbc_df, bbc_vocab)\n",
    "\n",
    "print(f\"Dataset comprises {len(bbc_df)} documents and {len(bbc_vocab.words)} unique words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_noise = NoiseDistribution(bbc_vocab)\n",
    "bbc_examples = list(example_generator(bbc_df, context_size=5, noise=bbc_noise, n_negative_samples=5, vocab=bbc_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_dataset = NCEDataset(bbc_examples)\n",
    "bbc_dataloader = DataLoader(bbc_dataset, batch_size=1024, drop_last=True, shuffle=True)  # TODO could tolerate a larger batch size\n",
    "\n",
    "bbc_model = DistributedMemory(vec_dim=50,\n",
    "                              n_docs=len(bbc_df),\n",
    "                              n_words=len(bbc_vocab.words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 80/80 [20:16<00:00, 15.21s/it]\n"
     ]
    }
   ],
   "source": [
    "bbc_training_losses = train(bbc_model, bbc_dataloader, epochs=80, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39msave(bbc_model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbbc_training_losses_weights.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(bbc_model.state_dict(), 'bbc_training_losses_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bbc\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomplete_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "bbc_model=torch.load('bbc_training_losses_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-76d95d7ad0d541c5a3309531cadc979f.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-76d95d7ad0d541c5a3309531cadc979f.vega-embed details,\n",
       "  #altair-viz-76d95d7ad0d541c5a3309531cadc979f.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-76d95d7ad0d541c5a3309531cadc979f\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-76d95d7ad0d541c5a3309531cadc979f\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-76d95d7ad0d541c5a3309531cadc979f\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-d8ec975c1e8a04d6f1de88960850b8f1\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"training_loss\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-d8ec975c1e8a04d6f1de88960850b8f1\": [{\"epoch\": 0, \"training_loss\": 2.6411681823044204}, {\"epoch\": 1, \"training_loss\": 2.1714515106257966}, {\"epoch\": 2, \"training_loss\": 1.9868299703740009}, {\"epoch\": 3, \"training_loss\": 1.8709007937914088}, {\"epoch\": 4, \"training_loss\": 1.787698035352579}, {\"epoch\": 5, \"training_loss\": 1.7225748201457798}, {\"epoch\": 6, \"training_loss\": 1.6684131459621874}, {\"epoch\": 7, \"training_loss\": 1.622296985266522}, {\"epoch\": 8, \"training_loss\": 1.5812197187106602}, {\"epoch\": 9, \"training_loss\": 1.544660657274516}, {\"epoch\": 10, \"training_loss\": 1.5110717137753225}, {\"epoch\": 11, \"training_loss\": 1.479967958578105}, {\"epoch\": 12, \"training_loss\": 1.451549120339803}, {\"epoch\": 13, \"training_loss\": 1.4247716162399973}, {\"epoch\": 14, \"training_loss\": 1.3998030554272105}, {\"epoch\": 15, \"training_loss\": 1.3764493268713467}, {\"epoch\": 16, \"training_loss\": 1.3542082509391065}, {\"epoch\": 17, \"training_loss\": 1.3329162927478477}, {\"epoch\": 18, \"training_loss\": 1.312822699990521}, {\"epoch\": 19, \"training_loss\": 1.2936244759311155}, {\"epoch\": 20, \"training_loss\": 1.2754822706170472}, {\"epoch\": 21, \"training_loss\": 1.2576792775549308}, {\"epoch\": 22, \"training_loss\": 1.2407336887295726}, {\"epoch\": 23, \"training_loss\": 1.2245335777107598}, {\"epoch\": 24, \"training_loss\": 1.2087298915640592}, {\"epoch\": 25, \"training_loss\": 1.1935399111092238}, {\"epoch\": 26, \"training_loss\": 1.1787116598550498}, {\"epoch\": 27, \"training_loss\": 1.1645911257556887}, {\"epoch\": 28, \"training_loss\": 1.1505920138607546}, {\"epoch\": 29, \"training_loss\": 1.1373685395747202}, {\"epoch\": 30, \"training_loss\": 1.1242331227948588}, {\"epoch\": 31, \"training_loss\": 1.1115419133277449}, {\"epoch\": 32, \"training_loss\": 1.099260291006074}, {\"epoch\": 33, \"training_loss\": 1.0871627585172061}, {\"epoch\": 34, \"training_loss\": 1.0755335693028074}, {\"epoch\": 35, \"training_loss\": 1.0641305969459542}, {\"epoch\": 36, \"training_loss\": 1.0530053873363854}, {\"epoch\": 37, \"training_loss\": 1.0421402897343741}, {\"epoch\": 38, \"training_loss\": 1.0313927676186667}, {\"epoch\": 39, \"training_loss\": 1.0210985456299841}, {\"epoch\": 40, \"training_loss\": 1.0109400230808827}, {\"epoch\": 41, \"training_loss\": 1.0010005850206238}, {\"epoch\": 42, \"training_loss\": 0.991377632907839}, {\"epoch\": 43, \"training_loss\": 0.9817383343321514}, {\"epoch\": 44, \"training_loss\": 0.9725311556761673}, {\"epoch\": 45, \"training_loss\": 0.9633613108257502}, {\"epoch\": 46, \"training_loss\": 0.9543575789437401}, {\"epoch\": 47, \"training_loss\": 0.9457256229728387}, {\"epoch\": 48, \"training_loss\": 0.9371311756280752}, {\"epoch\": 49, \"training_loss\": 0.9286692688985735}, {\"epoch\": 50, \"training_loss\": 0.9204809588770713}, {\"epoch\": 51, \"training_loss\": 0.9123242322179875}, {\"epoch\": 52, \"training_loss\": 0.9044773661469112}, {\"epoch\": 53, \"training_loss\": 0.896772926779598}, {\"epoch\": 54, \"training_loss\": 0.8892302468012343}, {\"epoch\": 55, \"training_loss\": 0.8818104315188623}, {\"epoch\": 56, \"training_loss\": 0.874343523094731}, {\"epoch\": 57, \"training_loss\": 0.8673326060286822}, {\"epoch\": 58, \"training_loss\": 0.8602219846645005}, {\"epoch\": 59, \"training_loss\": 0.8532495074177499}, {\"epoch\": 60, \"training_loss\": 0.8465331919287925}, {\"epoch\": 61, \"training_loss\": 0.8397525192490287}, {\"epoch\": 62, \"training_loss\": 0.8333093430061198}, {\"epoch\": 63, \"training_loss\": 0.8268420780562881}, {\"epoch\": 64, \"training_loss\": 0.8204670578019495}, {\"epoch\": 65, \"training_loss\": 0.8141765260962636}, {\"epoch\": 66, \"training_loss\": 0.8081514142435182}, {\"epoch\": 67, \"training_loss\": 0.8021311314762674}, {\"epoch\": 68, \"training_loss\": 0.7961031617804734}, {\"epoch\": 69, \"training_loss\": 0.7904189729660971}, {\"epoch\": 70, \"training_loss\": 0.7846857186582484}, {\"epoch\": 71, \"training_loss\": 0.7791464927770364}, {\"epoch\": 72, \"training_loss\": 0.7735529658812151}, {\"epoch\": 73, \"training_loss\": 0.7681089749850942}, {\"epoch\": 74, \"training_loss\": 0.7628299460813366}, {\"epoch\": 75, \"training_loss\": 0.7575225613401191}, {\"epoch\": 76, \"training_loss\": 0.7523032841700182}, {\"epoch\": 77, \"training_loss\": 0.7473075880158332}, {\"epoch\": 78, \"training_loss\": 0.7423416269624203}, {\"epoch\": 79, \"training_loss\": 0.7374578048810178}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(pd.DataFrame(enumerate(bbc_training_losses), columns=[\"epoch\", \"training_loss\"])).mark_bar().encode(x=\"epoch\", y=\"training_loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Echemos un vistazo a los vectores de párrafo de dimensionalidad reducida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-component PCA, explains 2.64% of variance\n"
     ]
    }
   ],
   "source": [
    "bbc_2d = pca_2d(bbc_model.paragraph_matrix.data, bbc_df.group.to_numpy())\n",
    "chart = alt.Chart(bbc_2d).mark_point().encode(x=\"x\", y=\"y\", color=\"group\")\n",
    "# Uncomment to print chart inline, but beware it will inflate the notebook size\n",
    "#chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2-component PCA, explains 2.65% of variance`\n",
    "\n",
    "![](./img/bbc_pca_all_topics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos resultados no son magníficos, pero podemos ver los inicios de la separación. Si nos fijamos en sólo dos temas, se hace más evidente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = alt.Chart(bbc_2d[bbc_2d[\"group\"].isin([\"sport\", \"business\"])]).mark_point().encode(x=\"x\", y=\"y\", color=\"group\")\n",
    "# Uncomment to print chart inline, but beware it will inflate the notebook size\n",
    "#chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/bbc_pca_business_sport.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del mismo modo, podemos ver que la clasificación por similitud produce resultados razonables, pero no ideales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>similarity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Claxton hunting first major medal  British hurdler Sarah Claxton is confident she can win her fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>477</td>\n",
       "      <td>0.495819</td>\n",
       "      <td>Clijsters hope on Aussie Open  Kim Clijsters has denied reports that she has pulled out of Janua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>486</td>\n",
       "      <td>0.469268</td>\n",
       "      <td>Officials respond in court row  Australian tennis' top official has defended the Australian Open...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>762</td>\n",
       "      <td>0.460628</td>\n",
       "      <td>BT offers equal access to rivals  BT has moved to pre-empt a possible break-up of its business b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0.454369</td>\n",
       "      <td>Bekele sets sights on world mark  Olympic 10,000m champion Kenenisa Bekele is determined to add ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>1059</td>\n",
       "      <td>0.442762</td>\n",
       "      <td>'Hitler' row over Welsh arts cash  An artist critical of Welsh arts funding being brought under ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>288</td>\n",
       "      <td>0.442663</td>\n",
       "      <td>Fuming Robinson blasts officials  England coach Andy Robinson insisted he was 'livid' after his ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>223</td>\n",
       "      <td>0.435558</td>\n",
       "      <td>Bristol City 2-1 Milton Keynes  Leroy Lita took his goal tally to 13 for the season as his doubl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>405</td>\n",
       "      <td>0.434914</td>\n",
       "      <td>Fuming Robinson blasts officials  England coach Andy Robinson said he was 'livid' after his side...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>0.432069</td>\n",
       "      <td>Ronaldo considering new contract  Manchester United winger Cristiano Ronaldo said he is close to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      doc_id  similarity  \\\n",
       "0          0    1.000000   \n",
       "477      477    0.495819   \n",
       "486      486    0.469268   \n",
       "762      762    0.460628   \n",
       "31        31    0.454369   \n",
       "1059    1059    0.442762   \n",
       "288      288    0.442663   \n",
       "223      223    0.435558   \n",
       "405      405    0.434914   \n",
       "97        97    0.432069   \n",
       "\n",
       "                                                                                                     text  \n",
       "0     Claxton hunting first major medal  British hurdler Sarah Claxton is confident she can win her fi...  \n",
       "477   Clijsters hope on Aussie Open  Kim Clijsters has denied reports that she has pulled out of Janua...  \n",
       "486   Officials respond in court row  Australian tennis' top official has defended the Australian Open...  \n",
       "762   BT offers equal access to rivals  BT has moved to pre-empt a possible break-up of its business b...  \n",
       "31    Bekele sets sights on world mark  Olympic 10,000m champion Kenenisa Bekele is determined to add ...  \n",
       "1059  'Hitler' row over Welsh arts cash  An artist critical of Welsh arts funding being brought under ...  \n",
       "288   Fuming Robinson blasts officials  England coach Andy Robinson insisted he was 'livid' after his ...  \n",
       "223   Bristol City 2-1 Milton Keynes  Leroy Lita took his goal tally to 13 for the season as his doubl...  \n",
       "405   Fuming Robinson blasts officials  England coach Andy Robinson said he was 'livid' after his side...  \n",
       "97    Ronaldo considering new contract  Manchester United winger Cristiano Ronaldo said he is close to...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(bbc_model.paragraph_matrix.data, bbc_df, 0, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para continuar con esto, podríamos:\n",
    "\n",
    "- buscar mejores hiperparámetros, ya que la pérdida de entrenamiento sigue siendo bastante alta\n",
    "- comparar con `gensim` y la implementación de PyTorch de Ilenic; debería ser muy similar a esta última\n",
    "- implementar el paso de inferencia para nuevos documentos, que congela las matrices de palabras y de salida y añade una nueva columna a la matriz de párrafos\n",
    "- utilizar los vectores de párrafos inferidos como entrada para un clasificador de temas; si se observa el gráfico de negocios/deportes anterior, podría tener bastante éxito\n",
    "- probar la visualización con un algoritmo de reducción de la dimensionalidad mejor que PCA (he utilizado [LargeVis](https://arxiv.org/abs/1602.00370) en el pasado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios:\n",
    "\n",
    "**Fundamentos y Conceptos Teóricos**\n",
    "\n",
    "1) ¿Qué es Doc2Vec y cómo se diferencia de Word2Vec?\n",
    "2) Explica cómo Doc2Vec representa documentos en vectores.\n",
    "3) Describe los dos principales modelos de entrenamiento de Doc2Vec: Distributed Memory (DM) y Distributed Bag of Words (DBOW).\n",
    "4) ¿Cómo contribuye el contexto de las palabras al aprendizaje de las representaciones vectoriales en Doc2Vec?\n",
    "\n",
    "**Detalles Técnicos y Entrenamiento**\n",
    "\n",
    "5) ¿Qué papel juegan los identificadores únicos de documentos en el modelo Doc2Vec?\n",
    "6) Explica cómo se entrena un modelo Doc2Vec y qué significa \"inferir\" un vector para un nuevo documento.\n",
    "7) ¿Cuáles son los principales hiperparámetros en Doc2Vec y cómo afectan al modelo?\n",
    "\n",
    "**Aplicaciones Prácticas**\n",
    "\n",
    "8) ¿En qué tipos de tareas de procesamiento de lenguaje natural (NLP) se puede utilizar Doc2Vec?\n",
    "9) Proporciona un ejemplo de cómo Doc2Vec podría mejorar un sistema de recomendación de artículos o productos.\n",
    "10) ¿Cómo se podría utilizar Doc2Vec para la detección de similitud entre documentos?\n",
    "\n",
    "**Comparaciones y Contrastes**\n",
    "\n",
    "11) Compara Doc2Vec con modelos basados en bolsas de palabras (bag-of-words). ¿Qué ventajas ofrece Doc2Vec?\n",
    "12) ¿En qué se diferencia Doc2Vec de los modelos de embeddings de palabras más recientes, como BERT o GPT?\n",
    "\n",
    "**Reflexión Crítica y Limitaciones**\n",
    "\n",
    "13) ¿Cuáles son las limitaciones de Doc2Vec en comparación con los enfoques de representación de texto basados en transformers?\n",
    "14) Discute el impacto de la longitud del documento en la calidad de las representaciones vectoriales en Doc2Vec.\n",
    "15) Reflexiona sobre cómo la elección del corpus de entrenamiento puede influir en la eficacia de los vectores generados por Doc2Vec para tareas específicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referencias:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Notes on Noise Contrastive Estimation and Negative Sampling (C. Dyer)](https://arxiv.org/abs/1410.8251) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapatado de:\n",
    "\n",
    "* https://github.com/cbowdon/doc2vec-pytorch/blob/master/doc2vec.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Lenguaje Matemático](./Images/Matematicas.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Contacto](./Images/Contacto.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
